{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b29504ea",
   "metadata": {},
   "source": [
    "## Library Installation\n",
    "Before running the notebook, ensure that the required libraries are installed. You can install them using the following commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38da2839",
   "metadata": {},
   "source": [
    "# OSM Features Extraction for Air Quality Data\n",
    "This notebook extracts OpenStreetMap features based on latitude and longitude for air quality data labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d869d3",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "Import libraries such as pandas, requests, and any mapping libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e95b696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-3.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (79 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting geopy\n",
      "  Using cached geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting overpy\n",
      "  Downloading overpy-0.7-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.4.1-cp313-cp313-macosx_14_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Using cached geographiclib-2.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-3.0.0-cp313-cp313-macosx_11_0_arm64.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m373.9 kB/s\u001b[0m  \u001b[33m0:00:25\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl (208 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "Using cached geographiclib-2.1-py3-none-any.whl (40 kB)\n",
      "Downloading overpy-0.7-py3-none-any.whl (14 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Downloading numpy-2.4.1-cp313-cp313-macosx_14_0_arm64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m403.4 kB/s\u001b[0m  \u001b[33m0:00:12\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, overpy, numpy, idna, geographiclib, charset_normalizer, certifi, requests, pandas, geopy\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [geopy]m 8/10\u001b[0m [pandas]hiclib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed certifi-2026.1.4 charset_normalizer-3.4.4 geographiclib-2.1 geopy-2.4.1 idna-3.11 numpy-2.4.1 overpy-0.7 pandas-3.0.0 requests-2.32.5 urllib3-2.6.3\n"
     ]
    }
   ],
   "source": [
    "# Library Installation\n",
    "!pip install pandas requests geopy overpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b57d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from geopy.geocoders import Nominatim\n",
    "import overpy\n",
    "\n",
    "# Initialize Overpass API\n",
    "api = overpy.Overpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb5e1c",
   "metadata": {},
   "source": [
    "## Load Station Locations from CSV\n",
    "Load the station locations from the provided CSV file using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e80925b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      station_name station_id   latitude  \\\n",
      "0                SIDCO Kurichi, Coimbatore - TNPCB  site_5094  10.942451   \n",
      "1                    Urban, Chamarajanagar - KSPCB  site_5124  11.553580   \n",
      "2                    MD University, Rohtak - HSPCB   site_147  28.521230   \n",
      "3  IESD Banaras Hindu University, Varanasi - UPPCB  site_5468  25.262326   \n",
      "4                           Sirifort, Delhi - CPCB   site_119  28.550425   \n",
      "\n",
      "   longitude  city  state  \n",
      "0  76.978996   NaN    NaN  \n",
      "1  76.555210   NaN    NaN  \n",
      "2  76.371380   NaN    NaN  \n",
      "3  82.995408   NaN    NaN  \n",
      "4  77.215938   NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "# Load Station Locations from CSV\n",
    "df_stations = pd.read_csv('station_locations.csv')\n",
    "print(df_stations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7715fc",
   "metadata": {},
   "source": [
    "## Define Function to Fetch OSM Features\n",
    "Create a function that takes latitude and longitude as input and fetches relevant OSM features using an API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function to Fetch OSM Features\n",
    "\n",
    "def fetch_osm_features(lat, lon):\n",
    "    # Define your Overpass API query here\n",
    "    query = f'[out:json];(node(around:500,{lat},{lon}););out;'\n",
    "    result = api.query(query)\n",
    "    relevant_features = []\n",
    "    for node in result.nodes:\n",
    "        features = node.tags\n",
    "        # Check for relevant features\n",
    "        if any(feature in features for feature in ['aerialway', 'amenity', 'building', 'highway', 'landuse', 'natural', 'shop']):\n",
    "            relevant_features.append(features)\n",
    "    return relevant_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad8d51c",
   "metadata": {},
   "source": [
    "## Map Latitude and Longitude to OSM Features\n",
    "Iterate through the station locations and use the function to map each location to its corresponding OSM features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db1fa5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying Overpass API for station: SIDCO Kurichi, Coimbatore - TNPCB\n",
      "Location: 10.942451, 76.978996\n",
      "Bounding box: 10.937451,76.973996,10.947451000000001,76.98399599999999\n",
      "\n",
      "Response status code: 200\n",
      "Response content type: application/json\n",
      "Response preview (first 500 chars):\n",
      "{\n",
      "  \"version\": 0.6,\n",
      "  \"generator\": \"Overpass API 0.7.62.10 2d4cfc48\",\n",
      "  \"osm3s\": {\n",
      "    \"timestamp_osm_base\": \"2026-01-28T11:07:55Z\",\n",
      "    \"copyright\": \"The data included in this document is from www.openstreetmap.org. The data is made available under ODbL.\"\n",
      "  },\n",
      "  \"elements\": [\n",
      "\n",
      "{\n",
      "  \"type\": \"node\",\n",
      "  \"id\": 266585747,\n",
      "  \"lat\": 10.9391913,\n",
      "  \"lon\": 76.9810669\n",
      "},\n",
      "{\n",
      "  \"type\": \"node\",\n",
      "  \"id\": 266585748,\n",
      "  \"lat\": 10.9392998,\n",
      "  \"lon\": 76.9799146\n",
      "},\n",
      "{\n",
      "  \"type\": \"node\",\n",
      "  \"id\": 1423799063,\n",
      "  \"lat\": 10.937\n",
      "\n",
      "✓ Successfully received data!\n",
      "Number of elements: 22953\n",
      "\n",
      "First 3 elements:\n",
      "\n",
      "Element 1:\n",
      "  Type: node\n",
      "  ID: 266585747\n",
      "  Tags: {}\n",
      "\n",
      "Element 2:\n",
      "  Type: node\n",
      "  ID: 266585748\n",
      "  Tags: {}\n",
      "\n",
      "Element 3:\n",
      "  Type: node\n",
      "  ID: 1423799063\n",
      "  Tags: {}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "# Example: bounding box around the first station (small area, ~500m buffer)\n",
    "lat = float(df_stations.iloc[0]['latitude'])\n",
    "lon = float(df_stations.iloc[0]['longitude'])\n",
    "delta = 0.005  # ~500m in degrees\n",
    "\n",
    "bbox = f\"{lat-delta},{lon-delta},{lat+delta},{lon+delta}\"\n",
    "\n",
    "query = f\"\"\"\n",
    "[bbox:{bbox}]\n",
    "[out:json]\n",
    "[timeout:90];\n",
    "(\n",
    "  node({lat-delta},{lon-delta},{lat+delta},{lon+delta});\n",
    "  way({lat-delta},{lon-delta},{lat+delta},{lon+delta});\n",
    "  relation({lat-delta},{lon-delta},{lat+delta},{lon+delta});\n",
    ");\n",
    "out body;\n",
    ">;\n",
    "out skel qt;\n",
    "\"\"\"\n",
    "\n",
    "url = \"https://overpass-api.de/api/interpreter\"\n",
    "\n",
    "print(f\"Querying Overpass API for station: {df_stations.iloc[0]['station_name']}\")\n",
    "print(f\"Location: {lat}, {lon}\")\n",
    "print(f\"Bounding box: {bbox}\\n\")\n",
    "\n",
    "# Add error handling\n",
    "try:\n",
    "    response = requests.post(url, data={'data': query}, timeout=120)\n",
    "    \n",
    "    print(f\"Response status code: {response.status_code}\")\n",
    "    print(f\"Response content type: {response.headers.get('Content-Type', 'Unknown')}\")\n",
    "    \n",
    "    # Check if response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Print first 500 chars of response to debug\n",
    "        print(f\"Response preview (first 500 chars):\\n{response.text[:500]}\\n\")\n",
    "        \n",
    "        # Try to parse JSON\n",
    "        data = response.json()\n",
    "        \n",
    "        # Print a summary of the result\n",
    "        print(f\"✓ Successfully received data!\")\n",
    "        print(f\"Number of elements: {len(data.get('elements', []))}\")\n",
    "        \n",
    "        if data.get('elements'):\n",
    "            print(f\"\\nFirst 3 elements:\")\n",
    "            for i, elem in enumerate(data['elements'][:3]):\n",
    "                print(f\"\\nElement {i+1}:\")\n",
    "                print(f\"  Type: {elem.get('type')}\")\n",
    "                print(f\"  ID: {elem.get('id')}\")\n",
    "                print(f\"  Tags: {elem.get('tags', {})}\")\n",
    "    elif response.status_code == 429:\n",
    "        print(\"⚠ Rate limited! Too many requests. Wait a moment and try again.\")\n",
    "    elif response.status_code == 504:\n",
    "        print(\"⚠ Gateway timeout! The query took too long. Try reducing the search area.\")\n",
    "    else:\n",
    "        print(f\"⚠ Error: {response.status_code}\")\n",
    "        print(f\"Response text:\\n{response.text[:1000]}\")\n",
    "        \n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"⚠ Request timed out! The server took too long to respond.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"⚠ Request failed: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"⚠ Failed to parse JSON response: {e}\")\n",
    "    print(f\"Response text:\\n{response.text[:1000]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e953ce1d",
   "metadata": {},
   "source": [
    "## Label Mapping for Air Quality Data\n",
    "Create a mapping of the fetched OSM features to labels relevant for air quality data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3088ef50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting OSM feature labels...\n",
      "\n",
      "======================================================================\n",
      "OSM FEATURE LABELS EXTRACTION RESULTS\n",
      "======================================================================\n",
      "Total OSM elements found: 22953\n",
      "Unique feature types: 6\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "EXTRACTED FEATURE LABELS BY CATEGORY\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "AMENITY:\n",
      "  Labels: college,fuel\n",
      "  Count of unique values: 2\n",
      "\n",
      "BARRIER:\n",
      "  Labels: gate\n",
      "  Count of unique values: 1\n",
      "\n",
      "BOUNDARY:\n",
      "  Labels: administrative\n",
      "  Count of unique values: 1\n",
      "\n",
      "HIGHWAY:\n",
      "  Labels: residential,service,tertiary,trunk,unclassified\n",
      "  Count of unique values: 5\n",
      "\n",
      "LANDUSE:\n",
      "  Labels: industrial\n",
      "  Count of unique values: 1\n",
      "\n",
      "RAILWAY:\n",
      "  Labels: rail\n",
      "  Count of unique values: 1\n",
      "\n",
      "======================================================================\n",
      "FEATURE DATAFRAME CREATED\n",
      "======================================================================\n",
      "Shape: (1, 12)\n",
      "Columns: 12\n",
      "\n",
      "Columns: ['station_id', 'station_name', 'latitude', 'longitude', 'barrier', 'highway', 'railway', 'landuse', 'amenity', 'boundary', '_total_elements', '_unique_feature_types']\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SAMPLE DATA (First Row)\n",
      "----------------------------------------------------------------------\n",
      "station_id          : site_5094\n",
      "station_name        : SIDCO Kurichi, Coimbatore - TNPCB\n",
      "latitude            : 10.942451\n",
      "longitude           : 76.978996\n",
      "barrier             : gate\n",
      "highway             : residential,service,tertiary,trunk,unclassified\n",
      "railway             : rail\n",
      "landuse             : industrial\n",
      "amenity             : college,fuel\n",
      "boundary            : administrative\n",
      "\n",
      "✓ Feature label extraction complete!\n",
      "  Each column contains comma-separated labels for that feature type.\n",
      "  This labeled data can be used for air quality prediction!\n"
     ]
    }
   ],
   "source": [
    "# Extract OSM Feature Labels for ML Training\n",
    "def extract_osm_feature_labels(osm_data):\n",
    "    \"\"\"\n",
    "    Extract OSM features as LABELS (not counts).\n",
    "    Each primary feature key becomes a column with comma-separated values.\n",
    "    \n",
    "    Example output:\n",
    "    - highway: \"trunk,secondary,residential\"\n",
    "    - landuse: \"industrial,commercial\"\n",
    "    - amenity: \"fuel,parking,hospital\"\n",
    "    \n",
    "    Returns:\n",
    "        dict: Feature labels {key: \"value1,value2,value3\"}\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    # Store unique values for each feature key\n",
    "    feature_values = defaultdict(set)\n",
    "    \n",
    "    # PRIMARY feature keys from OSM Map Features\n",
    "    primary_feature_keys = {\n",
    "        'aerialway', 'aeroway', 'highway', 'railway', 'public_transport',\n",
    "        'landuse', 'natural', 'leisure', 'place', 'building',\n",
    "        'amenity', 'shop', 'tourism', 'office',\n",
    "        'man_made', 'power', 'craft', 'industrial',\n",
    "        'emergency', 'healthcare',\n",
    "        'waterway', 'water', 'geological',\n",
    "        'barrier', 'boundary', 'historic', 'military', 'sport'\n",
    "    }\n",
    "    \n",
    "    # Process OSM elements\n",
    "    elements = osm_data.get('elements', [])\n",
    "    total_elements = len(elements)\n",
    "    \n",
    "    for element in elements:\n",
    "        tags = element.get('tags', {})\n",
    "        \n",
    "        for key, value in tags.items():\n",
    "            # ONLY include primary feature keys\n",
    "            if key not in primary_feature_keys:\n",
    "                continue\n",
    "            \n",
    "            # Skip generic/non-informative values\n",
    "            skip_values = ['yes', 'no', 'unknown', '']\n",
    "            if value in skip_values:\n",
    "                continue\n",
    "            \n",
    "            # Clean the value\n",
    "            safe_value = str(value).replace(' ', '_').replace(':', '_').replace('-', '_').replace(',', '_').replace('/', '_').replace('.', '_')\n",
    "            \n",
    "            # Add to set (automatically handles duplicates)\n",
    "            feature_values[key].add(safe_value)\n",
    "    \n",
    "    # Convert sets to comma-separated strings\n",
    "    feature_labels = {}\n",
    "    for key, values in feature_values.items():\n",
    "        # Sort values for consistency\n",
    "        sorted_values = sorted(list(values))\n",
    "        feature_labels[key] = ','.join(sorted_values)\n",
    "    \n",
    "    # Add metadata\n",
    "    feature_labels['_total_elements'] = total_elements\n",
    "    feature_labels['_unique_feature_types'] = len(feature_values)\n",
    "    \n",
    "    return feature_labels, feature_values\n",
    "\n",
    "\n",
    "# Apply feature extraction to the data we retrieved\n",
    "if 'data' in locals() and data.get('elements'):\n",
    "    print(\"Extracting OSM feature labels...\\n\")\n",
    "    feature_labels, feature_values_dict = extract_osm_feature_labels(data)\n",
    "    \n",
    "    # Display the feature extraction results\n",
    "    print(\"=\" * 70)\n",
    "    print(\"OSM FEATURE LABELS EXTRACTION RESULTS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Total OSM elements found: {feature_labels.get('_total_elements', 0)}\")\n",
    "    print(f\"Unique feature types: {feature_labels.get('_unique_feature_types', 0)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"EXTRACTED FEATURE LABELS BY CATEGORY\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Display features by category\n",
    "    for key in sorted(feature_values_dict.keys()):\n",
    "        values = feature_labels[key]\n",
    "        value_list = values.split(',')\n",
    "        print(f\"\\n{key.upper()}:\")\n",
    "        print(f\"  Labels: {values}\")\n",
    "        print(f\"  Count of unique values: {len(value_list)}\")\n",
    "    \n",
    "    # Create DataFrame for this station\n",
    "    feature_df = pd.DataFrame([feature_labels])\n",
    "    feature_df.insert(0, 'station_id', df_stations.iloc[0]['station_id'])\n",
    "    feature_df.insert(1, 'station_name', df_stations.iloc[0]['station_name'])\n",
    "    feature_df.insert(2, 'latitude', df_stations.iloc[0]['latitude'])\n",
    "    feature_df.insert(3, 'longitude', df_stations.iloc[0]['longitude'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"FEATURE DATAFRAME CREATED\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Shape: {feature_df.shape}\")\n",
    "    print(f\"Columns: {len(feature_df.columns)}\")\n",
    "    print(f\"\\nColumns: {list(feature_df.columns)}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"SAMPLE DATA (First Row)\")\n",
    "    print(\"-\" * 70)\n",
    "    for col in feature_df.columns:\n",
    "        if not col.startswith('_'):\n",
    "            print(f\"{col:20s}: {feature_df[col].iloc[0]}\")\n",
    "    \n",
    "    print(\"\\n✓ Feature label extraction complete!\")\n",
    "    print(\"  Each column contains comma-separated labels for that feature type.\")\n",
    "    print(\"  This labeled data can be used for air quality prediction!\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠ No OSM data available. Please run the previous cell to fetch data first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac129a0c",
   "metadata": {},
   "source": [
    "## Save Mapped Features to CSV\n",
    "Save the mapped features and labels to a new CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6be239a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Feature data saved to 'station_osm_features.csv'\n",
      "  - Rows: 1\n",
      "  - Columns: 12\n",
      "\n",
      "This CSV can be used for ML model training to predict air quality based on location features!\n"
     ]
    }
   ],
   "source": [
    "# Save Extracted Features to CSV\n",
    "if 'feature_df' in locals():\n",
    "    output_file = 'station_osm_features.csv'\n",
    "    feature_df.to_csv(output_file, index=False)\n",
    "    print(f\"✓ Feature data saved to '{output_file}'\")\n",
    "    print(f\"  - Rows: {len(feature_df)}\")\n",
    "    print(f\"  - Columns: {len(feature_df.columns)}\")\n",
    "    print(f\"\\nThis CSV can be used for ML model training to predict air quality based on location features!\")\n",
    "else:\n",
    "    print(\"⚠ No feature data to save. Please run the feature extraction cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16fee23",
   "metadata": {},
   "source": [
    "## Batch Process Multiple Stations\n",
    "Process multiple stations with automatic retry and rate limiting (5 second delay between requests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "398fe40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing for 25 stations...\n",
      "Delay between requests: 5 seconds\n",
      "======================================================================\n",
      "\n",
      "[1/25] Processing: SIDCO Kurichi, Coimbatore - TNPCB\n",
      "  Location: (10.942451, 76.978996)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ⚠ Gateway timeout! Waiting 15 seconds...\n",
      "  Querying Overpass API... (attempt 2/5)\n",
      "  ✓ Success! Received 22953 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[2/25] Processing: Urban, Chamarajanagar - KSPCB\n",
      "  Location: (11.55358, 76.55521)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 13203 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[3/25] Processing: MD University, Rohtak - HSPCB\n",
      "  Location: (28.52123, 76.37138)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ⚠ Gateway timeout! Waiting 15 seconds...\n",
      "  Querying Overpass API... (attempt 2/5)\n",
      "  ✓ Success! Received 905 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[4/25] Processing: IESD Banaras Hindu University, Varanasi - UPPCB\n",
      "  Location: (25.262326, 82.995408)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 7604 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[5/25] Processing: Sirifort, Delhi - CPCB\n",
      "  Location: (28.5504249, 77.2159377)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ⚠ Gateway timeout! Waiting 15 seconds...\n",
      "  Querying Overpass API... (attempt 2/5)\n",
      "  ✓ Success! Received 11277 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[6/25] Processing: Corporation Ground, Thrissur - Kerala PCB\n",
      "  Location: (10.5324, 76.2159)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 13435 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[7/25] Processing: Mangala, Bilaspur - NTPC\n",
      "  Location: (22.08815, 82.13737)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 16463 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[8/25] Processing: Civil Lines, Bareilly - UPPCB\n",
      "  Location: (28.359581, 79.414455)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 9535 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[9/25] Processing: Hardev Nagar, Bathinda - PPCB\n",
      "  Location: (30.233011, 74.907758)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 21005 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[10/25] Processing: Chalai Bazaar, Ramanathapuram - TNPCB\n",
      "  Location: (9.36399, 78.831977)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 29291 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[11/25] Processing: Lodhi Road, Delhi - IITM\n",
      "  Location: (28.588333, 77.221667)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ⚠ Gateway timeout! Waiting 15 seconds...\n",
      "  Querying Overpass API... (attempt 2/5)\n",
      "  ⚠ Gateway timeout! Waiting 15 seconds...\n",
      "  Querying Overpass API... (attempt 3/5)\n",
      "  ✓ Success! Received 12472 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[12/25] Processing: Worli, Mumbai - MPCB\n",
      "  Location: (18.9936162, 72.8128113)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 312156 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[13/25] Processing: Velachery Res. Area, Chennai - CPCB\n",
      "  Location: (13.0052189, 80.2398125)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 12305 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[14/25] Processing: Kandivali East, Mumbai - MPCB\n",
      "  Location: (19.2058, 72.8682)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 54654 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[15/25] Processing: Deen Dayal Nagar, Sagar - MPPCB\n",
      "  Location: (23.8640158, 78.80289321)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 17391 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[16/25] Processing: Sector-2 IMT, Manesar - HSPCB\n",
      "  Location: (28.360699, 76.93609)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 37668 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[17/25] Processing: Manali Village, Chennai - TNPCB\n",
      "  Location: (13.1662, 80.2584)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ⚠ Rate limited! Waiting 15 seconds...\n",
      "  Querying Overpass API... (attempt 2/5)\n",
      "  ⚠ Gateway timeout! Waiting 15 seconds...\n",
      "  Querying Overpass API... (attempt 3/5)\n",
      "  ✓ Success! Received 3433 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[18/25] Processing: DTU, Delhi - CPCB\n",
      "  Location: (28.7500499, 77.1112615)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 5545 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[19/25] Processing: IGI Airport (T3), Delhi - IMD\n",
      "  Location: (28.5627763, 77.1180053)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ⚠ Gateway timeout! Waiting 15 seconds...\n",
      "  Querying Overpass API... (attempt 2/5)\n",
      "  ✓ Success! Received 5377 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[20/25] Processing: Pusa, Delhi - IMD\n",
      "  Location: (28.63611, 77.173332)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 12764 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[21/25] Processing: Aya Nagar, Delhi - IMD\n",
      "  Location: (28.4706914, 77.1099364)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 16015 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[22/25] Processing: Lodhi Road, Delhi - IMD\n",
      "  Location: (28.5918245, 77.2273074)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 15439 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[23/25] Processing: Vasundhara, Ghaziabad - UPPCB\n",
      "  Location: (28.6603346, 77.3572563)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 8339 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[24/25] Processing: Sector - 125, Noida - UPPCB\n",
      "  Location: (28.5447608, 77.3231257)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ⚠ Gateway timeout! Waiting 15 seconds...\n",
      "  Querying Overpass API... (attempt 2/5)\n",
      "  ✓ Success! Received 168202 elements\n",
      "  Waiting 5 seconds before next request...\n",
      "\n",
      "[25/25] Processing: ITO, Delhi - CPCB\n",
      "  Location: (28.628624, 77.24106)\n",
      "  Querying Overpass API... (attempt 1/5)\n",
      "  ✓ Success! Received 113388 elements\n",
      "\n",
      "======================================================================\n",
      "BATCH PROCESSING COMPLETE\n",
      "======================================================================\n",
      "Successfully processed: 25 stations\n",
      "Failed: 0 stations\n",
      "\n",
      "DataFrame shape: (25, 30)\n",
      "Columns: 30\n",
      "\n",
      "✓ Saved to 'station_osm_features_batch_25.csv'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SUMMARY OF EXTRACTED FEATURES\n",
      "----------------------------------------------------------------------\n",
      "  station_id                                     station_name   latitude  \\\n",
      "0  site_5094                SIDCO Kurichi, Coimbatore - TNPCB  10.942451   \n",
      "1  site_5124                    Urban, Chamarajanagar - KSPCB  11.553580   \n",
      "2   site_147                    MD University, Rohtak - HSPCB  28.521230   \n",
      "3  site_5468  IESD Banaras Hindu University, Varanasi - UPPCB  25.262326   \n",
      "4   site_119                           Sirifort, Delhi - CPCB  28.550425   \n",
      "\n",
      "   longitude  _total_elements  _unique_feature_types aeroway  \\\n",
      "0  76.978996            22953                      6     NaN   \n",
      "1  76.555210            13203                      1     NaN   \n",
      "2  76.371380              905                      3     NaN   \n",
      "3  82.995408             7604                     16     NaN   \n",
      "4  77.215938            11277                     18     NaN   \n",
      "\n",
      "                                             amenity  \\\n",
      "0                                       college,fuel   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  atm,bank,bar,bicycle_parking,cafe,community_ce...   \n",
      "4  bench,cafe,charging_station,clinic,college,con...   \n",
      "\n",
      "                                             barrier        boundary  ...  \\\n",
      "0                                               gate  administrative  ...   \n",
      "1                                                NaN             NaN  ...   \n",
      "2                                                NaN             NaN  ...   \n",
      "3                                          gate,wall             NaN  ...   \n",
      "4  bollard,city_wall,cycle_barrier,entrance,fence...  administrative  ...   \n",
      "\n",
      "                                 office                   place  \\\n",
      "0                                   NaN                     NaN   \n",
      "1                                   NaN                     NaN   \n",
      "2                                   NaN                     NaN   \n",
      "3      educational_institution,research  locality,neighbourhood   \n",
      "4  company,diplomatic,government,lawyer    neighbourhood,suburb   \n",
      "\n",
      "             power public_transport railway  \\\n",
      "0              NaN              NaN    rail   \n",
      "1              NaN              NaN     NaN   \n",
      "2       line,tower              NaN    rail   \n",
      "3       substation              NaN     NaN   \n",
      "4  pole,substation         platform     NaN   \n",
      "\n",
      "                                                shop  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  bathroom_furnishing,motorcycle_repair,supermar...   \n",
      "4  art,bakery,beauty,boutique,clothes,electrical,...   \n",
      "\n",
      "                                               sport         tourism water  \\\n",
      "0                                                NaN             NaN   NaN   \n",
      "1                                                NaN             NaN   NaN   \n",
      "2                                                NaN             NaN   NaN   \n",
      "3                  cricket,cricket;athletics;running          hostel   NaN   \n",
      "4  basketball,cricket,soccer,squash;badminton,ten...  gallery,museum   NaN   \n",
      "\n",
      "  waterway  \n",
      "0      NaN  \n",
      "1      NaN  \n",
      "2      NaN  \n",
      "3      NaN  \n",
      "4      NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Batch Process Multiple Stations\n",
    "import time\n",
    "\n",
    "# ========== CONFIGURATION ==========\n",
    "NUM_STATIONS = 25  # Change this to process more stations\n",
    "DELAY_SECONDS = 5  # Delay between requests to avoid rate limiting\n",
    "RETRY_DELAY = 15  # Delay after a failed request before retrying\n",
    "# ===================================\n",
    "\n",
    "print(f\"Starting batch processing for {NUM_STATIONS} stations...\")\n",
    "print(f\"Delay between requests: {DELAY_SECONDS} seconds\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Storage for all station features\n",
    "all_features = []\n",
    "failed_stations = []\n",
    "\n",
    "for idx in range(min(NUM_STATIONS, len(df_stations))):\n",
    "    station = df_stations.iloc[idx]\n",
    "    station_id = station['station_id']\n",
    "    station_name = station['station_name']\n",
    "    lat = float(station['latitude'])\n",
    "    lon = float(station['longitude'])\n",
    "    \n",
    "    print(f\"\\n[{idx+1}/{NUM_STATIONS}] Processing: {station_name}\")\n",
    "    print(f\"  Location: ({lat}, {lon})\")\n",
    "    \n",
    "    # Build Overpass query\n",
    "    delta = 0.005\n",
    "    bbox = f\"{lat-delta},{lon-delta},{lat+delta},{lon+delta}\"\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    [bbox:{bbox}]\n",
    "    [out:json]\n",
    "    [timeout:90];\n",
    "    (\n",
    "      node({lat-delta},{lon-delta},{lat+delta},{lon+delta});\n",
    "      way({lat-delta},{lon-delta},{lat+delta},{lon+delta});\n",
    "      relation({lat-delta},{lon-delta},{lat+delta},{lon+delta});\n",
    "    );\n",
    "    out body;\n",
    "    >;\n",
    "    out skel qt;\n",
    "    \"\"\"\n",
    "    \n",
    "    url = \"https://overpass-api.de/api/interpreter\"\n",
    "    \n",
    "    # Try to fetch data with retry logic\n",
    "    max_retries = 5\n",
    "    retry_count = 0\n",
    "    success = False\n",
    "    \n",
    "    while retry_count < max_retries and not success:\n",
    "        try:\n",
    "            print(f\"  Querying Overpass API... (attempt {retry_count+1}/{max_retries})\")\n",
    "            response = requests.post(url, data={'data': query}, timeout=120)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                elements_count = len(data.get('elements', []))\n",
    "                print(f\"  ✓ Success! Received {elements_count} elements\")\n",
    "                \n",
    "                # Extract feature labels\n",
    "                feature_labels, _ = extract_osm_feature_labels(data)\n",
    "                \n",
    "                # Add station metadata\n",
    "                feature_labels['station_id'] = station_id\n",
    "                feature_labels['station_name'] = station_name\n",
    "                feature_labels['latitude'] = lat\n",
    "                feature_labels['longitude'] = lon\n",
    "                \n",
    "                all_features.append(feature_labels)\n",
    "                success = True\n",
    "                \n",
    "            elif response.status_code == 429:\n",
    "                print(f\"  ⚠ Rate limited! Waiting {RETRY_DELAY} seconds...\")\n",
    "                time.sleep(RETRY_DELAY)\n",
    "                retry_count += 1\n",
    "                \n",
    "            elif response.status_code == 504:\n",
    "                print(f\"  ⚠ Gateway timeout! Waiting {RETRY_DELAY} seconds...\")\n",
    "                time.sleep(RETRY_DELAY)\n",
    "                retry_count += 1\n",
    "                \n",
    "            else:\n",
    "                print(f\"  ⚠ Error {response.status_code}: {response.text[:200]}\")\n",
    "                retry_count += 1\n",
    "                \n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"  ⚠ Request timed out! Waiting {RETRY_DELAY} seconds...\")\n",
    "            time.sleep(RETRY_DELAY)\n",
    "            retry_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠ Error: {e}\")\n",
    "            retry_count += 1\n",
    "    \n",
    "    if not success:\n",
    "        print(f\"  ✗ Failed after {max_retries} attempts\")\n",
    "        failed_stations.append({'station_id': station_id, 'station_name': station_name})\n",
    "    \n",
    "    # Wait before next request (except for the last one)\n",
    "    if idx < NUM_STATIONS - 1:\n",
    "        print(f\"  Waiting {DELAY_SECONDS} seconds before next request...\")\n",
    "        time.sleep(DELAY_SECONDS)\n",
    "\n",
    "# Create final DataFrame\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BATCH PROCESSING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Successfully processed: {len(all_features)} stations\")\n",
    "print(f\"Failed: {len(failed_stations)} stations\")\n",
    "\n",
    "if all_features:\n",
    "    # Create DataFrame with all features\n",
    "    batch_df = pd.DataFrame(all_features)\n",
    "    \n",
    "    # Reorder columns: station info first, then features\n",
    "    info_cols = ['station_id', 'station_name', 'latitude', 'longitude']\n",
    "    feature_cols = [col for col in batch_df.columns if col not in info_cols]\n",
    "    batch_df = batch_df[info_cols + sorted(feature_cols)]\n",
    "    \n",
    "    print(f\"\\nDataFrame shape: {batch_df.shape}\")\n",
    "    print(f\"Columns: {len(batch_df.columns)}\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = f'station_osm_features_batch_{NUM_STATIONS}.csv'\n",
    "    batch_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✓ Saved to '{output_file}'\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"SUMMARY OF EXTRACTED FEATURES\")\n",
    "    print(\"-\" * 70)\n",
    "    print(batch_df.head())\n",
    "    \n",
    "else:\n",
    "    print(\"\\n⚠ No data was successfully extracted!\")\n",
    "\n",
    "if failed_stations:\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"FAILED STATIONS\")\n",
    "    print(\"-\" * 70)\n",
    "    for failed in failed_stations:\n",
    "        print(f\"  - {failed['station_name']} ({failed['station_id']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
