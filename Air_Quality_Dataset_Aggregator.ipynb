{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dafe064d",
   "metadata": {},
   "source": [
    "# Air Quality Dataset Aggregator\n",
    "\n",
    "This notebook merges air quality data from multiple CSV files, filters by station ID, adds user-defined attributes, and splits the output into multiple files with a maximum of 10,000 rows each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0e2c60",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b36225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe9ed5",
   "metadata": {},
   "source": [
    "## Section 2: Define User Input Parameters\n",
    "\n",
    "Enter the station ID and the values for the new columns to be added to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8fb8843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading unified OSM features...\n",
      "✓ Loaded 230 stations from unified features\n",
      "\n",
      "Total feature columns: 26\n",
      "Feature columns: ['aeroway', 'amenity', 'barrier', 'boundary', 'building', 'craft', 'emergency', 'healthcare', 'highway', 'historic', 'industrial', 'landuse', 'leisure', 'man_made', 'military', 'natural', 'office', 'place', 'power', 'public_transport', 'railway', 'shop', 'sport', 'tourism', 'water', 'waterway']\n",
      "\n",
      "First 5 stations (station info + first few features):\n",
      "  station_id                                     station_name aeroway  \\\n",
      "0      TN005                SIDCO Kurichi, Coimbatore - TNPCB     NaN   \n",
      "1      KA012                    Urban, Chamarajanagar - KSPCB     NaN   \n",
      "2      HR026                    MD University, Rohtak - HSPCB     NaN   \n",
      "3      UP026  IESD Banaras Hindu University, Varanasi - UPPCB     NaN   \n",
      "4      DL034                           Sirifort, Delhi - CPCB     NaN   \n",
      "\n",
      "                                             amenity  \\\n",
      "0                                       college,fuel   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  atm,bank,bar,bicycle_parking,cafe,community_ce...   \n",
      "4  bench,cafe,charging_station,clinic,college,con...   \n",
      "\n",
      "                                             barrier        boundary  \\\n",
      "0                                               gate  administrative   \n",
      "1                                                NaN             NaN   \n",
      "2                                                NaN             NaN   \n",
      "3                                          gate,wall             NaN   \n",
      "4  bollard,city_wall,cycle_barrier,entrance,fence...  administrative   \n",
      "\n",
      "                                           building  \n",
      "0                                               NaN  \n",
      "1                                               NaN  \n",
      "2                                               NaN  \n",
      "3              public,residential,school,university  \n",
      "4  apartments,college,house,residential,roof,school  \n",
      "\n",
      "✓ Ready to process all stations with ALL features automatically!\n"
     ]
    }
   ],
   "source": [
    "# Load the unified OSM features to get station data automatically\n",
    "current_directory = os.getcwd()\n",
    "unified_features_path = os.path.join(current_directory, \"station_osm_features_unified.csv\")\n",
    "\n",
    "print(\"Loading unified OSM features...\")\n",
    "df_unified_features = pd.read_csv(unified_features_path)\n",
    "print(f\"✓ Loaded {len(df_unified_features)} stations from unified features\")\n",
    "\n",
    "# Identify all feature columns (exclude metadata columns)\n",
    "metadata_cols = ['station_id', 'original_station_id', 'station_name', 'latitude', 'longitude', \n",
    "                 '_total_elements', '_unique_feature_types']\n",
    "feature_columns = [col for col in df_unified_features.columns if col not in metadata_cols]\n",
    "\n",
    "print(f\"\\nTotal feature columns: {len(feature_columns)}\")\n",
    "print(f\"Feature columns: {feature_columns}\")\n",
    "\n",
    "print(f\"\\nFirst 5 stations (station info + first few features):\")\n",
    "display_cols = ['station_id', 'station_name'] + feature_columns[:5]\n",
    "print(df_unified_features[display_cols].head())\n",
    "\n",
    "print(\"\\n✓ Ready to process all stations with ALL features automatically!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e13f1d",
   "metadata": {},
   "source": [
    "## Section 3: Load Station Hour Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9903872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading station_hour.csv from: /Users/likhithkanigolla/IIITH/code-files/Digital-Twin/Air-Quality-Dataset-Seggregator-DT/station_hour.csv\n",
      "✓ Station Hour DataFrame shape: (2589083, 16)\n",
      "  Columns: ['StationId', 'Datetime', 'PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'Xylene', 'AQI', 'AQI_Bucket']\n"
     ]
    }
   ],
   "source": [
    "# Load station_hour.csv data\n",
    "station_hour_path = os.path.join(current_directory, \"station_hour.csv\")\n",
    "\n",
    "print(f\"Loading station_hour.csv from: {station_hour_path}\")\n",
    "station_hour_df = pd.read_csv(station_hour_path)\n",
    "\n",
    "print(f\"✓ Station Hour DataFrame shape: {station_hour_df.shape}\")\n",
    "print(f\"  Columns: {list(station_hour_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a79cc",
   "metadata": {},
   "source": [
    "## Section 4: Process All Stations Automatically\n",
    "\n",
    "This section automatically processes each station from the unified features dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773d6763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "AUTOMATED STATION PROCESSING\n",
      "======================================================================\n",
      "✓ StationId found in station_hour.csv\n",
      "\n",
      "Total stations in unified features: 230\n",
      "Stations with air quality data: 96\n",
      "Stations to process: 96\n",
      "\n",
      "✓ Ready to process 96 stations\n"
     ]
    }
   ],
   "source": [
    "# Process all stations automatically\n",
    "print(\"=\" * 70)\n",
    "print(\"AUTOMATED STATION PROCESSING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check if StationId column exists\n",
    "if 'StationId' not in station_hour_df.columns:\n",
    "    print(\"✗ StationId not found in station_hour.csv\")\n",
    "    print(f\"Available columns: {list(station_hour_df.columns)}\")\n",
    "else:\n",
    "    print(\"✓ StationId found in station_hour.csv\")\n",
    "\n",
    "# Get list of stations to process (only those in station_hour data)\n",
    "available_stations = station_hour_df['StationId'].unique()\n",
    "stations_to_process = df_unified_features[df_unified_features['station_id'].isin(available_stations)]\n",
    "\n",
    "print(f\"\\nTotal stations in unified features: {len(df_unified_features)}\")\n",
    "print(f\"Stations with air quality data: {len(stations_to_process)}\")\n",
    "print(f\"Stations to process: {len(stations_to_process)}\")\n",
    "\n",
    "if len(stations_to_process) == 0:\n",
    "    print(\"\\n⚠️ Warning: No stations to process!\")\n",
    "else:\n",
    "    print(f\"\\n✓ Ready to process {len(stations_to_process)} stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c144639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "UNIQUE STATION IDs IN STATION_HOUR.CSV\n",
      "======================================================================\n",
      "Total unique stations: 110\n",
      "\n",
      "Station IDs:\n",
      "['AP001', 'AP005', 'AS001', 'BR005', 'BR006', 'BR007', 'BR008', 'BR009', 'BR010', 'CH001', 'DL001', 'DL002', 'DL003', 'DL004', 'DL005', 'DL006', 'DL007', 'DL008', 'DL009', 'DL010', 'DL011', 'DL012', 'DL013', 'DL014', 'DL015', 'DL016', 'DL017', 'DL018', 'DL019', 'DL020', 'DL021', 'DL022', 'DL023', 'DL024', 'DL025', 'DL026', 'DL027', 'DL028', 'DL029', 'DL030', 'DL031', 'DL032', 'DL033', 'DL034', 'DL035', 'DL036', 'DL037', 'DL038', 'GJ001', 'HR011', 'HR012', 'HR013', 'HR014', 'JH001', 'KA002', 'KA003', 'KA004', 'KA005', 'KA006', 'KA007', 'KA008', 'KA009', 'KA010', 'KA011', 'KL002', 'KL004', 'KL007', 'KL008', 'MH005', 'MH006', 'MH007', 'MH008', 'MH009', 'MH010', 'MH011', 'MH012', 'MH013', 'MH014', 'ML001', 'MP001', 'MZ001', 'OD001', 'OD002', 'PB001', 'RJ004', 'RJ005', 'RJ006', 'TG001', 'TG002', 'TG003', 'TG004', 'TG005', 'TG006', 'TN001', 'TN002', 'TN003', 'TN004', 'TN005', 'UP012', 'UP013', 'UP014', 'UP015', 'UP016', 'WB007', 'WB008', 'WB009', 'WB010', 'WB011', 'WB012', 'WB013']\n"
     ]
    }
   ],
   "source": [
    "# Check unique StationId values in station_hour.csv\n",
    "unique_station_ids = station_hour_df['StationId'].unique()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"UNIQUE STATION IDs IN STATION_HOUR.CSV\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total unique stations: {len(unique_station_ids)}\")\n",
    "print(f\"\\nStation IDs:\")\n",
    "print(sorted(unique_station_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc39eb",
   "metadata": {},
   "source": [
    "## Filter Unified Features for Stations with Air Quality Data\n",
    "\n",
    "Create a filtered version of the unified features containing only the 110 stations that have air quality data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5292a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering unified features for stations with air quality data...\n",
      "======================================================================\n",
      "Original unified features: 230 stations\n",
      "Filtered unified features: 96 stations\n",
      "Stations excluded: 134 stations\n",
      "\n",
      "✓ Saved filtered dataset to 'station_osm_features_filtered_110.csv'\n",
      "  - Rows: 96\n",
      "  - Columns: 33\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "FILTERED DATASET SUMMARY\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "First 5 stations in filtered dataset:\n",
      "   station_id                         station_name   latitude  longitude\n",
      "0       TN005    SIDCO Kurichi, Coimbatore - TNPCB  10.942451  76.978996\n",
      "4       DL034               Sirifort, Delhi - CPCB  28.550425  77.215938\n",
      "10      DL017             Lodhi Road, Delhi - IITM  28.588333  77.221667\n",
      "11      MH014                 Worli, Mumbai - MPCB  18.993616  72.812811\n",
      "12      TN004  Velachery Res. Area, Chennai - CPCB  13.005219  80.239812\n",
      "\n",
      "All 96 filtered station IDs:\n",
      "['AP001', 'AP005', 'AS001', 'BR005', 'BR006', 'BR007', 'BR009', 'BR010', 'CH001', 'DL001', 'DL002', 'DL003', 'DL004', 'DL005', 'DL007', 'DL008', 'DL009', 'DL010', 'DL012', 'DL013', 'DL014', 'DL015', 'DL016', 'DL017', 'DL017', 'DL018', 'DL019', 'DL020', 'DL022', 'DL023', 'DL024', 'DL025', 'DL026', 'DL027', 'DL028', 'DL029', 'DL030', 'DL031', 'DL032', 'DL033', 'DL034', 'DL035', 'DL036', 'DL037', 'DL038', 'GJ001', 'HR011', 'HR013', 'HR014', 'JH001', 'KA003', 'KA005', 'KA010', 'KL002', 'KL004', 'KL008', 'MH005', 'MH005', 'MH006', 'MH006', 'MH007', 'MH008', 'MH009', 'MH010', 'MH011', 'MH012', 'MH013', 'MH014', 'MP001', 'MZ001', 'OD001', 'OD002', 'PB001', 'RJ004', 'RJ005', 'RJ006', 'TG001', 'TG003', 'TG004', 'TG005', 'TG006', 'TN002', 'TN003', 'TN004', 'TN005', 'UP013', 'UP014', 'UP015', 'UP016', 'WB007', 'WB008', 'WB009', 'WB010', 'WB011', 'WB012', 'WB013']\n"
     ]
    }
   ],
   "source": [
    "# Filter unified features to only include stations with air quality data\n",
    "print(\"Filtering unified features for stations with air quality data...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Filter the unified features dataframe\n",
    "df_unified_filtered = df_unified_features[df_unified_features['station_id'].isin(unique_station_ids)].copy()\n",
    "\n",
    "print(f\"Original unified features: {len(df_unified_features)} stations\")\n",
    "print(f\"Filtered unified features: {len(df_unified_filtered)} stations\")\n",
    "print(f\"Stations excluded: {len(df_unified_features) - len(df_unified_filtered)} stations\")\n",
    "\n",
    "# Save the filtered dataset\n",
    "output_file = 'station_osm_features_filtered_110.csv'\n",
    "df_unified_filtered.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved filtered dataset to '{output_file}'\")\n",
    "print(f\"  - Rows: {len(df_unified_filtered)}\")\n",
    "print(f\"  - Columns: {len(df_unified_filtered.columns)}\")\n",
    "\n",
    "# Show some statistics\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"FILTERED DATASET SUMMARY\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\nFirst 5 stations in filtered dataset:\")\n",
    "display_cols = ['station_id', 'station_name', 'latitude', 'longitude']\n",
    "print(df_unified_filtered[display_cols].head())\n",
    "\n",
    "print(f\"\\nAll {len(df_unified_filtered)} filtered station IDs:\")\n",
    "print(sorted(df_unified_filtered['station_id'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d60cd3",
   "metadata": {},
   "source": [
    "## Section 5: Process Each Station with Features\n",
    "\n",
    "This section loops through each station, filters the data, adds OSM features, and saves to chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da081e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting automated processing of 96 stations...\n",
      "======================================================================\n",
      "\n",
      "[1/96] Processing: TN005 - SIDCO Kurichi, Coimbatore - TNPCB\n",
      "  Found 9229 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/TN005/\n",
      "\n",
      "[2/96] Processing: DL034 - Sirifort, Delhi - CPCB\n",
      "  Found 32051 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 4 chunk file(s) to output/DL034/\n",
      "\n",
      "[3/96] Processing: DL017 - Lodhi Road, Delhi - IITM\n",
      "  Found 24662 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL017/\n",
      "\n",
      "[4/96] Processing: MH014 - Worli, Mumbai - MPCB\n",
      "  Found 9255 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/MH014/\n",
      "\n",
      "[5/96] Processing: TN004 - Velachery Res. Area, Chennai - CPCB\n",
      "  Found 48192 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/TN004/\n",
      "\n",
      "[6/96] Processing: TN002 - Manali Village, Chennai - TNPCB\n",
      "  Found 9072 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/TN002/\n",
      "\n",
      "[7/96] Processing: DL008 - DTU, Delhi - CPCB\n",
      "  Found 48192 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/DL008/\n",
      "\n",
      "[8/96] Processing: DL012 - IGI Airport (T3), Delhi - IMD\n",
      "  Found 24840 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL012/\n",
      "\n",
      "[9/96] Processing: DL030 - Pusa, Delhi - IMD\n",
      "  Found 24683 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL030/\n",
      "\n",
      "[10/96] Processing: DL004 - Aya Nagar, Delhi - IMD\n",
      "  Found 24661 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL004/\n",
      "\n",
      "[11/96] Processing: DL017 - Lodhi Road, Delhi - IMD\n",
      "  Found 24662 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL017/\n",
      "\n",
      "[12/96] Processing: DL014 - ITO, Delhi - CPCB\n",
      "  Found 48128 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/DL014/\n",
      "\n",
      "[13/96] Processing: DL007 - CRRI Mathura Road, Delhi - IMD\n",
      "  Found 48192 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/DL007/\n",
      "\n",
      "[14/96] Processing: DL025 - North Campus, DU, Delhi - IMD\n",
      "  Found 24840 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL025/\n",
      "\n",
      "[15/96] Processing: DL013 - IHBAS, Dilshad Garden, Delhi - CPCB\n",
      "  Found 48192 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/DL013/\n",
      "\n",
      "[16/96] Processing: DL033 - Shadipur, Delhi - CPCB\n",
      "  Found 48192 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/DL033/\n",
      "\n",
      "[17/96] Processing: DL019 - Mandir Marg, Delhi - DPCC\n",
      "  Found 45826 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/DL019/\n",
      "\n",
      "[18/96] Processing: DL031 - R K Puram, Delhi - DPCC\n",
      "  Found 45950 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/DL031/\n",
      "\n",
      "[19/96] Processing: DL028 - Punjabi Bagh, Delhi - DPCC\n",
      "  Found 45872 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/DL028/\n",
      "\n",
      "[20/96] Processing: HR014 - Vikas Sadan, Gurugram - HSPCB\n",
      "  Found 40258 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/HR014/\n",
      "\n",
      "[21/96] Processing: MH005 - Bandra, Mumbai - MPCB\n",
      "  Found 48192 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/MH005/\n",
      "\n",
      "[22/96] Processing: KA003 - BWSSB Kadabesanahalli, Bengaluru - CPCB\n",
      "  Found 48192 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/KA003/\n",
      "\n",
      "[23/96] Processing: RJ005 - Police Commissionerate, Jaipur - RSPCB\n",
      "  Found 26705 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/RJ005/\n",
      "\n",
      "[24/96] Processing: TG003 - ICRISAT Patancheru, Hyderabad - TSPCB\n",
      "  Found 29558 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/TG003/\n",
      "\n",
      "[25/96] Processing: KL008 - Plammoodu, Thiruvananthapuram - Kerala PCB\n",
      "  Found 26651 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/KL008/\n",
      "\n",
      "[26/96] Processing: JH001 - Tata Stadium, Jorapokhar - JSPCB\n",
      "  Found 28025 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/JH001/\n",
      "\n",
      "[27/96] Processing: PB001 - Golden Temple, Amritsar - PPCB\n",
      "  Found 29269 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/PB001/\n",
      "\n",
      "[28/96] Processing: AP005 - GVM Corporation, Visakhapatnam - APPCB\n",
      "  Found 35053 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 4 chunk file(s) to output/AP005/\n",
      "\n",
      "[29/96] Processing: KA005 - City Railway Station, Bengaluru - KSPCB\n",
      "  Found 40667 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/KA005/\n",
      "\n",
      "[30/96] Processing: KA010 - Sanegurava Halli, Bengaluru - KSPCB\n",
      "  Found 40736 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/KA010/\n",
      "\n",
      "[31/96] Processing: TG001 - Bollaram Industrial Area, Hyderabad - TSPCB\n",
      "  Found 29558 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/TG001/\n",
      "\n",
      "[32/96] Processing: BR007 - IGSC Planetarium Complex, Patna - BSPCB\n",
      "  Found 44554 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/BR007/\n",
      "\n",
      "[33/96] Processing: TG004 - IDA Pashamylaram, Hyderabad - TSPCB\n",
      "  Found 33565 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 4 chunk file(s) to output/TG004/\n",
      "\n",
      "[34/96] Processing: UP014 - Lalbagh, Lucknow - CPCB\n",
      "  Found 48192 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/UP014/\n",
      "\n",
      "[35/96] Processing: TG005 - Sanathnagar, Hyderabad - TSPCB\n",
      "  Found 48107 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/TG005/\n",
      "\n",
      "[36/96] Processing: WB011 - Rabindra Bharati University, Kolkata - WBPCB\n",
      "  Found 14463 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 2 chunk file(s) to output/WB011/\n",
      "\n",
      "[37/96] Processing: UP016 - Talkatora District Industries Center, Lucknow - CPCB\n",
      "  Found 24199 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/UP016/\n",
      "\n",
      "[38/96] Processing: TG006 - Zoo Park, Hyderabad - TSPCB\n",
      "  Found 42321 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/TG006/\n",
      "\n",
      "[39/96] Processing: DL002 - Anand Vihar, Delhi - DPCC\n",
      "  Found 45950 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/DL002/\n",
      "\n",
      "[40/96] Processing: TN003 - Manali, Chennai - CPCB\n",
      "  Found 48192 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/TN003/\n",
      "\n",
      "[41/96] Processing: GJ001 - Maninagar, Ahmedabad - GPCB\n",
      "  Found 48192 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/GJ001/\n",
      "\n",
      "[42/96] Processing: WB013 - Victoria, Kolkata - WBPCB\n",
      "  Found 19503 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 2 chunk file(s) to output/WB013/\n",
      "\n",
      "[43/96] Processing: RJ004 - Adarsh Nagar, Jaipur - RSPCB\n",
      "  Found 23793 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/RJ004/\n",
      "\n",
      "[44/96] Processing: RJ006 - Shastri Nagar, Jaipur - RSPCB\n",
      "  Found 23534 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/RJ006/\n",
      "\n",
      "[45/96] Processing: UP015 - Nishant Ganj, Lucknow - UPPCB\n",
      "  Found 18082 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 2 chunk file(s) to output/UP015/\n",
      "\n",
      "[46/96] Processing: AP001 - Secretariat, Amaravati - APPCB\n",
      "  Found 22784 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/AP001/\n",
      "\n",
      "[47/96] Processing: OD002 - Talcher Coalfields,Talcher - OSPCB\n",
      "  Found 22161 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/OD002/\n",
      "\n",
      "[48/96] Processing: OD001 - GM Office, Brajrajnagar - OSPCB\n",
      "  Found 22468 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/OD001/\n",
      "\n",
      "[49/96] Processing: DL003 - Ashok Vihar, Delhi - DPCC\n",
      "  Found 21136 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL003/\n",
      "\n",
      "[50/96] Processing: DL009 - Dr. Karni Singh Shooting Range, Delhi - DPCC\n",
      "  Found 21136 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL009/\n",
      "\n",
      "[51/96] Processing: DL010 - Dwarka-Sector 8, Delhi - DPCC \n",
      "  Found 21137 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL010/\n",
      "\n",
      "[52/96] Processing: DL015 - Jahangirpuri, Delhi - DPCC\n",
      "  Found 21136 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL015/\n",
      "\n",
      "[53/96] Processing: DL016 - Jawaharlal Nehru Stadium, Delhi - DPCC\n",
      "  Found 21136 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL016/\n",
      "\n",
      "[54/96] Processing: DL018 - Major Dhyan Chand National Stadium, Delhi - DPCC\n",
      "  Found 21144 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL018/\n",
      "\n",
      "[55/96] Processing: DL023 - Narela, Delhi - DPCC\n",
      "  Found 21134 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL023/\n",
      "\n",
      "[56/96] Processing: DL022 - Najafgarh, Delhi - DPCC\n",
      "  Found 21134 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL022/\n",
      "\n",
      "[57/96] Processing: DL026 - Okhla Phase-2, Delhi - DPCC\n",
      "  Found 21134 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL026/\n",
      "\n",
      "[58/96] Processing: DL024 - Nehru Nagar, Delhi - DPCC\n",
      "  Found 21134 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL024/\n",
      "\n",
      "[59/96] Processing: DL032 - Rohini, Delhi - DPCC\n",
      "  Found 21134 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL032/\n",
      "\n",
      "[60/96] Processing: DL027 - Patparganj, Delhi - DPCC\n",
      "  Found 21134 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL027/\n",
      "\n",
      "[61/96] Processing: DL035 - Sonia Vihar, Delhi - DPCC\n",
      "  Found 21134 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL035/\n",
      "\n",
      "[62/96] Processing: DL038 - Wazirpur, Delhi - DPCC\n",
      "  Found 21134 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL038/\n",
      "\n",
      "[63/96] Processing: DL037 - Vivek Vihar, Delhi - DPCC\n",
      "  Found 21134 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/DL037/\n",
      "\n",
      "[64/96] Processing: DL005 - Bawana, Delhi - DPCC\n",
      "  Found 17454 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 2 chunk file(s) to output/DL005/\n",
      "\n",
      "[65/96] Processing: DL020 - Mundka, Delhi - DPCC\n",
      "  Found 17478 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 2 chunk file(s) to output/DL020/\n",
      "\n",
      "[66/96] Processing: DL036 - Sri Aurobindo Marg, Delhi - DPCC\n",
      "  Found 17478 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 2 chunk file(s) to output/DL036/\n",
      "\n",
      "[67/96] Processing: DL029 - Pusa, Delhi - DPCC\n",
      "  Found 17478 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 2 chunk file(s) to output/DL029/\n",
      "\n",
      "[68/96] Processing: DL001 - Alipur, Delhi - DPCC\n",
      "  Found 14338 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 2 chunk file(s) to output/DL001/\n",
      "\n",
      "[69/96] Processing: HR011 - NISE Gwal Pahari, Gurugram - IMD\n",
      "  Found 21912 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 3 chunk file(s) to output/HR011/\n",
      "\n",
      "[70/96] Processing: AS001 - Railway Colony, Guwahati - PCBA\n",
      "  Found 12002 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 2 chunk file(s) to output/AS001/\n",
      "\n",
      "[71/96] Processing: MH012 - Vasai West, Mumbai - MPCB\n",
      "  Found 9442 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/MH012/\n",
      "\n",
      "[72/96] Processing: MH009 - Kurla, Mumbai - MPCB\n",
      "  Found 9370 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/MH009/\n",
      "\n",
      "[73/96] Processing: MH013 - Vile Parle West, Mumbai - MPCB\n",
      "  Found 9441 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/MH013/\n",
      "\n",
      "[74/96] Processing: MH007 - Chhatrapati Shivaji Intl. Airport (T2), Mumbai - MPCB\n",
      "  Found 9423 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/MH007/\n",
      "\n",
      "[75/96] Processing: WB009 - Fort William, Kolkata - WBPCB\n",
      "  Found 9516 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/WB009/\n",
      "\n",
      "[76/96] Processing: WB010 - Jadavpur, Kolkata - WBPCB\n",
      "  Found 9446 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/WB010/\n",
      "\n",
      "[77/96] Processing: MH010 - Powai, Mumbai - MPCB\n",
      "  Found 9422 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/MH010/\n",
      "\n",
      "[78/96] Processing: MH006 - Borivali East, Mumbai - MPCB\n",
      "  Found 9229 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/MH006/\n",
      "\n",
      "[79/96] Processing: MH011 - Sion, Mumbai - MPCB\n",
      "  Found 9035 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/MH011/\n",
      "\n",
      "[80/96] Processing: MH008 - Colaba, Mumbai - MPCB\n",
      "  Found 8941 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/MH008/\n",
      "\n",
      "[81/96] Processing: WB012 - Rabindra Sarobar, Kolkata - WBPCB\n",
      "  Found 7910 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/WB012/\n",
      "\n",
      "[82/96] Processing: CH001 - Sector-25, Chandigarh - CPCC\n",
      "  Found 7263 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/CH001/\n",
      "\n",
      "[83/96] Processing: UP013 - Gomti Nagar, Lucknow - UPPCB\n",
      "  Found 7545 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/UP013/\n",
      "\n",
      "[84/96] Processing: WB008 - Bidhannagar, Kolkata - WBPCB\n",
      "  Found 7545 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/WB008/\n",
      "\n",
      "[85/96] Processing: WB007 - Ballygunge, Kolkata - WBPCB\n",
      "  Found 7334 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/WB007/\n",
      "\n",
      "[86/96] Processing: MP001 - T T Nagar, Bhopal - MPPCB\n",
      "  Found 6903 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/MP001/\n",
      "\n",
      "[87/96] Processing: BR009 - Rajbansi Nagar, Patna - BSPCB\n",
      "  Found 4543 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/BR009/\n",
      "\n",
      "[88/96] Processing: BR010 - Samanpura, Patna - BSPCB\n",
      "  Found 4543 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/BR010/\n",
      "\n",
      "[89/96] Processing: KL004 - Vyttila, Kochi - Kerala PCB\n",
      "  Found 3854 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/KL004/\n",
      "\n",
      "[90/96] Processing: KL002 - Kacheripady, Ernakulam - Kerala PCB\n",
      "  Found 3852 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/KL002/\n",
      "\n",
      "[91/96] Processing: BR006 - Govt. High School Shikarpur, Patna - BSPCB\n",
      "  Found 2863 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/BR006/\n",
      "\n",
      "[92/96] Processing: BR005 - DRM Office Danapur, Patna - BSPCB\n",
      "  Found 2985 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/BR005/\n",
      "\n",
      "[93/96] Processing: HR013 - Teri Gram, Gurugram - HSPCB\n",
      "  Found 2817 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/HR013/\n",
      "\n",
      "[94/96] Processing: MZ001 - Sikulpuikawn, Aizawl - Mizoram PCB\n",
      "  Found 2680 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/MZ001/\n",
      "\n",
      "[95/96] Processing: MH005 - Bandra Kurla Complex, Mumbai - IITM\n",
      "  Found 48192 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 5 chunk file(s) to output/MH005/\n",
      "\n",
      "[96/96] Processing: MH006 - Borivali East, Mumbai - IITM\n",
      "  Found 9229 rows\n",
      "  Added 26 feature columns\n",
      "  ✓ Saved 1 chunk file(s) to output/MH006/\n",
      "\n",
      "======================================================================\n",
      "PROCESSING COMPLETE!\n",
      "======================================================================\n",
      "Total stations processed: 96/96\n",
      "Failed stations: 0\n",
      "Total files created: 270\n",
      "\n",
      "✓ All output files saved in 'output/' folder\n"
     ]
    }
   ],
   "source": [
    "# Loop through each station and process\n",
    "chunk_size = 10000\n",
    "total_stations = len(stations_to_process)\n",
    "processed_count = 0\n",
    "failed_count = 0\n",
    "total_files_created = 0\n",
    "\n",
    "print(f\"Starting automated processing of {total_stations} stations...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for idx, station_row in stations_to_process.iterrows():\n",
    "    station_id = station_row['station_id']\n",
    "    station_name = station_row['station_name']\n",
    "    \n",
    "    print(f\"\\n[{processed_count + 1}/{total_stations}] Processing: {station_id} - {station_name}\")\n",
    "    \n",
    "    try:\n",
    "        # Filter station_hour data for this station\n",
    "        filtered_df = station_hour_df[station_hour_df['StationId'] == station_id].copy()\n",
    "        \n",
    "        if filtered_df.shape[0] == 0:\n",
    "            print(f\"  ⚠️ No data found for {station_id}, skipping...\")\n",
    "            failed_count += 1\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Found {filtered_df.shape[0]} rows\")\n",
    "        \n",
    "        # Add ALL feature columns from unified dataset\n",
    "        for feature_col in feature_columns:\n",
    "            # Get the feature value for this station (handle NaN values)\n",
    "            feature_value = station_row[feature_col]\n",
    "            if pd.isna(feature_value):\n",
    "                feature_value = \"\"  # Empty string for missing features\n",
    "            filtered_df[feature_col] = feature_value\n",
    "        \n",
    "        print(f\"  Added {len(feature_columns)} feature columns\")\n",
    "        \n",
    "        # Create output folder for this station\n",
    "        output_folder = os.path.join(current_directory, \"output\", station_id)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        # Split into chunks and save\n",
    "        total_rows = filtered_df.shape[0]\n",
    "        num_chunks = (total_rows + chunk_size - 1) // chunk_size\n",
    "        \n",
    "        for i in range(num_chunks):\n",
    "            start_idx = i * chunk_size\n",
    "            end_idx = min((i + 1) * chunk_size, total_rows)\n",
    "            chunk_df = filtered_df.iloc[start_idx:end_idx]\n",
    "            \n",
    "            file_number = i + 1\n",
    "            filename = f\"{station_id}_chunk_{file_number}.csv\"\n",
    "            filepath = os.path.join(output_folder, filename)\n",
    "            \n",
    "            chunk_df.to_csv(filepath, index=False)\n",
    "            total_files_created += 1\n",
    "        \n",
    "        print(f\"  ✓ Saved {num_chunks} chunk file(s) to output/{station_id}/\")\n",
    "        processed_count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error processing {station_id}: {e}\")\n",
    "        failed_count += 1\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PROCESSING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total stations processed: {processed_count}/{total_stations}\")\n",
    "print(f\"Failed stations: {failed_count}\")\n",
    "print(f\"Total files created: {total_files_created}\")\n",
    "print(f\"\\n✓ All output files saved in 'output/' folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bf1d16",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This automated notebook:\n",
    "1. ✓ Loads the unified OSM features dataset\n",
    "2. ✓ Automatically identifies ALL feature columns (not just 6)\n",
    "3. ✓ Loads station_hour.csv with air quality data\n",
    "4. ✓ Processes each station automatically:\n",
    "   - Filters air quality data by station ID\n",
    "   - Adds ALL OSM feature columns from unified dataset\n",
    "   - Splits data into chunks of 10,000 rows\n",
    "   - Saves chunks to `output/[StationID]/` folder\n",
    "5. ✓ Provides detailed progress and summary statistics\n",
    "\n",
    "All output files are organized in the `output/` folder by station ID!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
